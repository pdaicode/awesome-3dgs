{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsXqtQVJ-6wS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Math utils"
      ],
      "metadata": {
        "id": "3tuwFOV__JfZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2D Gaussian Splatting implemented in python with a few lines of code\n",
        "\n",
        "\n",
        "\n",
        "This code implements the renderer of the paper \"2D Gaussian Splatting for Geometrically Accurate Radiance Fields\".\n",
        "\n",
        "paper: https://arxiv.org/abs/2403.17888\n",
        "\n",
        "homepage: https://surfsplatting.github.io/\n",
        "\n",
        "The cuda code is efficient and good, but it would be more readable with a pure pytorch/python code so readers can have better understanding without needing looking into the cuda implementation. Reader can also implement it with other preferred programming language.\n",
        "\n",
        "This code is built upon many great repos:\n",
        "\n",
        "torch-splatting: https://github.com/hbb1/torch-splatting\n",
        "\n",
        "3DGS: https://github.com/graphdeco-inria/gaussian-splatting\n",
        "\n",
        "gsplat: https://github.com/nerfstudio-project/gsplat"
      ],
      "metadata": {
        "id": "pcWh0PVWT7iC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_rotation(r):\n",
        "    norm = torch.sqrt(r[:,0]*r[:,0] + r[:,1]*r[:,1] + r[:,2]*r[:,2] + r[:,3]*r[:,3])\n",
        "\n",
        "    q = r / norm[:, None]\n",
        "\n",
        "    R = torch.zeros((q.size(0), 3, 3), device='cuda')\n",
        "\n",
        "    r = q[:, 0]\n",
        "    x = q[:, 1]\n",
        "    y = q[:, 2]\n",
        "    z = q[:, 3]\n",
        "\n",
        "    R[:, 0, 0] = 1 - 2 * (y*y + z*z)\n",
        "    R[:, 0, 1] = 2 * (x*y - r*z)\n",
        "    R[:, 0, 2] = 2 * (x*z + r*y)\n",
        "    R[:, 1, 0] = 2 * (x*y + r*z)\n",
        "    R[:, 1, 1] = 1 - 2 * (x*x + z*z)\n",
        "    R[:, 1, 2] = 2 * (y*z - r*x)\n",
        "    R[:, 2, 0] = 2 * (x*z - r*y)\n",
        "    R[:, 2, 1] = 2 * (y*z + r*x)\n",
        "    R[:, 2, 2] = 1 - 2 * (x*x + y*y)\n",
        "    return R\n",
        "\n",
        "def build_scaling_rotation(s, r):\n",
        "    L = torch.zeros((s.shape[0], 3, 3), dtype=torch.float, device=\"cuda\")\n",
        "    R = build_rotation(r)\n",
        "\n",
        "    L[:,0,0] = s[:,0]\n",
        "    L[:,1,1] = s[:,1]\n",
        "    L[:,2,2] = s[:,2]\n",
        "\n",
        "    L = R @ L\n",
        "    return L\n",
        "\n",
        "def getProjectionMatrix(znear, zfar, fovX, fovY):\n",
        "    import math\n",
        "    tanHalfFovY = math.tan((fovY / 2))\n",
        "    tanHalfFovX = math.tan((fovX / 2))\n",
        "\n",
        "    top = tanHalfFovY * znear\n",
        "    bottom = -top\n",
        "    right = tanHalfFovX * znear\n",
        "    left = -right\n",
        "\n",
        "    P = torch.zeros(4, 4)\n",
        "\n",
        "    z_sign = 1.0\n",
        "\n",
        "    P[0, 0] = 2.0 * znear / (right - left)\n",
        "    P[1, 1] = 2.0 * znear / (top - bottom)\n",
        "    P[0, 2] = (right + left) / (right - left)\n",
        "    P[1, 2] = (top + bottom) / (top - bottom)\n",
        "    P[3, 2] = z_sign\n",
        "    P[2, 2] = z_sign * zfar / (zfar - znear)\n",
        "    P[2, 3] = -(zfar * znear) / (zfar - znear)\n",
        "    return P\n",
        "\n",
        "def focal2fov(focal, pixels):\n",
        "    import math\n",
        "    return 2*math.atan(pixels/(2*focal))\n",
        "\n",
        "def homogeneous(points):\n",
        "    \"\"\"\n",
        "    homogeneous points\n",
        "    :param points: [..., 3]\n",
        "    \"\"\"\n",
        "    return torch.cat([points, torch.ones_like(points[..., :1])], dim=-1)\n",
        "\n",
        "def homogeneous_vec(vec):\n",
        "    \"\"\"\n",
        "    homogeneous points\n",
        "    :param points: [..., 3]\n",
        "    \"\"\"\n",
        "    return torch.cat([vec, torch.zeros_like(vec[..., :1])], dim=-1)"
      ],
      "metadata": {
        "id": "fhmSXACx_VL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Surface splatting (2D Gaussian splatting)"
      ],
      "metadata": {
        "id": "yjPjjw2y_qL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Surface splatting (2D Gaussian Splatting)\n",
        "def setup(means3D, scales, quats, opacities, colors, viewmat, projmat):\n",
        "    rotations = build_scaling_rotation(scales, quats).permute(0,2,1)\n",
        "\n",
        "    # 1. Viewing transform\n",
        "    # Eq.4 and Eq.5\n",
        "    p_view = (means3D @ viewmat[:3,:3]) + viewmat[-1:,:3]\n",
        "    uv_view = (rotations @ viewmat[:3,:3])\n",
        "    M = torch.cat([homogeneous_vec(uv_view[:,:2,:]), homogeneous(p_view.unsqueeze(1))], dim=1)\n",
        "\n",
        "    T = M @ projmat # T stands for (WH)^T in Eq.9\n",
        "    import pdb; pdb.set_trace()\n",
        "    # 2. Compute AABB\n",
        "    # Homogneous plane is very useful for both ray-splat intersection and bounding box computation\n",
        "    # we know how to compute u,v given x,y homogeneous plane already; computing AABB is done by a reverse process.\n",
        "    # i.e compute the x, y s.t. \\|hu^4\\| = 1 and \\|h_v^4\\|=1 (distance of gaussian center to plane in the uv space)\n",
        "    temp_point = torch.tensor([[1.,1., -1.]]).cuda()\n",
        "    distance = (temp_point * (T[..., 3] * T[..., 3])).sum(dim=-1, keepdims=True)\n",
        "    f = (1 / distance) * temp_point\n",
        "    point_image = torch.cat(\n",
        "        [(f * T[..., 0] * T[...,3]).sum(dim=-1, keepdims=True),\n",
        "        (f * T[..., 1] * T[...,3]).sum(dim=-1, keepdims=True),\n",
        "        (f * T[..., 2] * T[...,3]).sum(dim=-1, keepdims=True)], dim=-1)\n",
        "\n",
        "    half_extend = point_image * point_image - torch.cat(\n",
        "        [(f * T[..., 0] * T[...,0]).sum(dim=-1, keepdims=True),\n",
        "        (f * T[..., 1] * T[...,1]).sum(dim=-1, keepdims=True),\n",
        "        (f * T[..., 2] * T[...,2]).sum(dim=-1, keepdims=True)], dim=-1)\n",
        "\n",
        "    radii = half_extend.clamp(min=1e-4).sqrt() * 3 # three sigma\n",
        "    center = point_image\n",
        "\n",
        "    # 3. Perform Sorting\n",
        "    depth = p_view[..., 2] # depth is used only for sorting\n",
        "    index = depth.sort()[1]\n",
        "    T = T[index]\n",
        "    colors = colors[index]\n",
        "    center = center[index]\n",
        "    depth = depth[index]\n",
        "    radii = radii[index]\n",
        "    opacities = opacities[index]\n",
        "    return T, colors, opacities, center, depth, radii\n",
        "\n",
        "def surface_splatting(means3D, scales, quats, colors, opacities, intrins, viewmat, projmat):\n",
        "    # Rasterization setup\n",
        "    projmat = torch.zeros(4,4).cuda()\n",
        "    projmat[:3,:3] = intrins\n",
        "    projmat[-1,-2] = 1.0\n",
        "    projmat = projmat.T\n",
        "    T, colors, opacities, center, depth, radii = setup(means3D, scales, quats, opacities, colors, viewmat, projmat)\n",
        "\n",
        "    # Rasterization\n",
        "    # 1. Generate pixels\n",
        "    H, W = (intrins[0,-1] * 2).long(), (intrins[1,-1] * 2).long()\n",
        "    H, W = H.item(), W.item()\n",
        "    pix = torch.stack(torch.meshgrid(torch.arange(H),\n",
        "        torch.arange(W), indexing='xy'), dim=-1).to('cuda')\n",
        "\n",
        "    # 2. Compute ray splat intersection # Eq.9 and Eq.10\n",
        "    x = pix.reshape(-1,1,2)[..., :1]\n",
        "    y = pix.reshape(-1,1,2)[..., 1:]\n",
        "    k = -T[None][..., 0] + x * T[None][..., 3]\n",
        "    l = -T[None][..., 1] + y * T[None][..., 3]\n",
        "    points = torch.cross(k, l, dim=-1)\n",
        "    s = points[..., :2] / points[..., -1:]\n",
        "\n",
        "    # 3. add low pass filter # Eq. 11\n",
        "    # when a point (2D Gaussian) viewed from a far distance or from a slended angle\n",
        "    # the 2D Gaussian will falls between pixels and no fragment is used to rasterize the Gaussian\n",
        "    # so we should add a low pass filter to handle such aliasing.\n",
        "    dist3d = (s * s).sum(dim=-1)\n",
        "    filtersze = np.sqrt(2) / 2\n",
        "    dist2d = (1/filtersze)**2 * (torch.cat([x,y], dim=-1) - center[None,:,:2]).norm(dim=-1)**2\n",
        "    # min of dist2 is equal to max of Gaussian exp(-0.5 * dist2)\n",
        "    dist2 = torch.min(dist3d, dist2d)\n",
        "    # dist2 = dist3d\n",
        "    depth_acc = (homogeneous(s) * T[None,..., -1]).sum(dim=-1)\n",
        "\n",
        "    # 4. accumulate 2D gaussians through alpha blending # Eq.12\n",
        "    image, depthmap = alpha_blending_with_gaussians(dist2, colors, opacities, depth_acc, H, W)\n",
        "    return image, depthmap, center, radii, dist2"
      ],
      "metadata": {
        "id": "f4DBG-sz_tes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Volume splatting (3D Gaussian Splatting)"
      ],
      "metadata": {
        "id": "6PgnyA6JAE5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_covariance_2d(\n",
        "    mean3d, cov3d, viewmatrix, tan_fovx, tan_fovy, focal_x, focal_y\n",
        "):\n",
        "    import math\n",
        "    t = (mean3d @ viewmatrix[:3,:3]) + viewmatrix[-1:,:3]\n",
        "    tz = t[..., 2]\n",
        "    tx = t[..., 0]\n",
        "    ty = t[..., 1]\n",
        "\n",
        "    # Eq.29 locally affine transform\n",
        "    # perspective transform is not affine so we approximate with first-order taylor expansion\n",
        "    # notice that we multiply by the intrinsic so that the variance is at the sceen space\n",
        "    J = torch.zeros(mean3d.shape[0], 3, 3).to(mean3d)\n",
        "    J[..., 0, 0] = 1 / tz * focal_x\n",
        "    J[..., 0, 2] = -tx / (tz * tz) * focal_x\n",
        "    J[..., 1, 1] = 1 / tz * focal_y\n",
        "    J[..., 1, 2] = -ty / (tz * tz) * focal_y\n",
        "    W = viewmatrix[:3,:3].T # transpose to correct viewmatrix\n",
        "    cov2d = J @ W @ cov3d @ W.T @ J.permute(0,2,1)\n",
        "\n",
        "    # add low pass filter here according to E.q. 32\n",
        "    filter = torch.eye(2,2).to(cov2d) * 0.0\n",
        "    return cov2d[:, :2, :2] + filter[None]\n",
        "\n",
        "def build_covariance_3d(s, r):\n",
        "    L = build_scaling_rotation(s, r).permute(0,2,1)\n",
        "    actual_covariance = L @ L.transpose(1, 2)\n",
        "    return actual_covariance\n",
        "\n",
        "def projection_ndc(points, viewmatrix, projmatrix):\n",
        "    points_o = homogeneous(points) # object space\n",
        "    points_h = points_o @ viewmatrix @ projmatrix # screen space # RHS\n",
        "    p_w = 1.0 / (points_h[..., -1:] + 0.000001)\n",
        "    p_proj = points_h * p_w\n",
        "    p_view = points_o @ viewmatrix\n",
        "    in_mask = p_view[..., 2] >= 0.2\n",
        "    return p_proj, p_view, in_mask\n",
        "\n",
        "def get_radius(cov2d):\n",
        "    det = cov2d[:, 0, 0] * cov2d[:,1,1] - cov2d[:, 0, 1] * cov2d[:,1,0]\n",
        "    mid = 0.5 * (cov2d[:, 0,0] + cov2d[:,1,1])\n",
        "    lambda1 = mid + torch.sqrt((mid**2-det).clip(min=0.1))\n",
        "    lambda2 = mid - torch.sqrt((mid**2-det).clip(min=0.1))\n",
        "    return 3.0 * torch.sqrt(torch.max(lambda1, lambda2)).ceil()\n",
        "\n",
        "def volume_splatting(means3D, scales, quats, colors, opacities, intrins, viewmat, projmat):\n",
        "    projmat = torch.zeros(4,4).cuda()\n",
        "    projmat[:3,:3] = intrins\n",
        "    projmat[-1,-2] = 1.0\n",
        "    projmat = projmat.T\n",
        "\n",
        "    mean_ndc, mean_view, in_mask = projection_ndc(means3D, viewmatrix=viewmat, projmatrix=projmat)\n",
        "\n",
        "    depths = mean_view[:,2]\n",
        "    mean_coord_x = mean_ndc[..., 0]\n",
        "    mean_coord_y = mean_ndc[..., 1]\n",
        "\n",
        "    means2D = torch.stack([mean_coord_x, mean_coord_y], dim=-1)\n",
        "    # scales = torch.cat([scales[..., :2], scales[..., -1:]*1e-2], dim=-1)\n",
        "    cov3d = build_covariance_3d(scales, quats)\n",
        "\n",
        "    W, H = (intrins[0,-1] * 2).long().item(), (intrins[1,-1] * 2).long().item()\n",
        "    fx, fy = intrins[0,0], intrins[1,1]\n",
        "    tan_fovx = W / (2 * fx)\n",
        "    tan_fovy = H / (2 * fy)\n",
        "    cov2d = build_covariance_2d(means3D, cov3d, viewmat, tan_fovx, tan_fovy, fx, fy)\n",
        "    radii = get_radius(cov2d)\n",
        "\n",
        "    # Rasterization\n",
        "    # generate pixels\n",
        "    pix = torch.stack(torch.meshgrid(torch.arange(H), torch.arange(W), indexing='xy'), dim=-1).to('cuda').flatten(0,-2)\n",
        "    sorted_conic = cov2d.inverse() # inverse of variance\n",
        "    dx = (pix[:,None,:] - means2D[None,:]) # B P 2\n",
        "    dist2 = dx[:, :, 0]**2 * sorted_conic[:, 0, 0] + dx[:, :, 1]**2 * sorted_conic[:, 1, 1]+ dx[:,:,0]*dx[:,:,1] * sorted_conic[:, 0, 1]+ dx[:,:,0]*dx[:,:,1] * sorted_conic[:, 1, 0]\n",
        "    depth_acc = depths[None].expand_as(dist2)\n",
        "\n",
        "    image, depthmap = alpha_blending_with_gaussians(dist2, colors, opacities, depth_acc, H, W)\n",
        "    return image, depthmap, means2D, radii, dist2"
      ],
      "metadata": {
        "id": "THUjERtnANnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rendering utils"
      ],
      "metadata": {
        "id": "6h6bNW-6_XZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def alpha_blending(alpha, colors):\n",
        "  T = torch.cat([torch.ones_like(alpha[-1:]), (1-alpha).cumprod(dim=0)[:-1]], dim=0)\n",
        "  image = (T * alpha * colors).sum(dim=0).reshape(-1, colors.shape[-1])\n",
        "  alphamap = (T * alpha).sum(dim=0).reshape(-1, 1)\n",
        "  return image, alphamap\n",
        "\n",
        "\n",
        "def alpha_blending_with_gaussians(dist2, colors, opacities, depth_acc, H, W):\n",
        "    colors = colors.reshape(-1,1,colors.shape[-1])\n",
        "    depth_acc = depth_acc.T[..., None]\n",
        "    depth_acc = depth_acc.repeat(1,1,1)\n",
        "\n",
        "    # evaluate gaussians\n",
        "    # just for visualization, the actual cut off can be 3 sigma!\n",
        "    cutoff = 1**2\n",
        "    dist2 = dist2.T\n",
        "    gaussians = torch.exp(-0.5*dist2) * (dist2 < cutoff)\n",
        "    gaussians = gaussians[..., None]\n",
        "    alpha = opacities.unsqueeze(1) * gaussians\n",
        "\n",
        "    # accumulate gaussians\n",
        "    image, _ = alpha_blending(alpha, colors)\n",
        "    depthmap, alphamap = alpha_blending(alpha, depth_acc)\n",
        "    depthmap = depthmap / alphamap\n",
        "    depthmap = torch.nan_to_num(depthmap, 0, 0)\n",
        "    return image.reshape(H,W,-1), depthmap.reshape(H,W,-1)"
      ],
      "metadata": {
        "id": "2ulOShwp-2xW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils for inputs and cameras"
      ],
      "metadata": {
        "id": "YoyRlnsYARRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_inputs(num_points=8):\n",
        "    length = 0.5\n",
        "    x = np.linspace(-1, 1, num_points) * length\n",
        "    y = np.linspace(-1, 1, num_points) * length\n",
        "    x, y = np.meshgrid(x, y)\n",
        "    means3D = torch.from_numpy(np.stack([x,y, 0 * np.random.rand(*x.shape)], axis=-1).reshape(-1,3)).cuda().float()\n",
        "    quats = torch.zeros(1,4).repeat(len(means3D), 1).cuda()\n",
        "    quats[..., 0] = 1.\n",
        "    scale = length /(num_points-1)\n",
        "    scales = torch.zeros(1,3).repeat(len(means3D), 1).fill_(scale).cuda()\n",
        "    return means3D, scales, quats\n",
        "\n",
        "def get_cameras():\n",
        "    intrins = torch.tensor([[711.1111,   0.0000, 256.0000,   0.0000],\n",
        "               [  0.0000, 711.1111, 256.0000,   0.0000],\n",
        "               [  0.0000,   0.0000,   1.0000,   0.0000],\n",
        "               [  0.0000,   0.0000,   0.0000,   1.0000]]).cuda()\n",
        "    c2w = torch.tensor([[-8.6086e-01,  3.7950e-01, -3.3896e-01,  6.7791e-01],\n",
        "         [ 5.0884e-01,  6.4205e-01, -5.7346e-01,  1.1469e+00],\n",
        "         [ 1.0934e-08, -6.6614e-01, -7.4583e-01,  1.4917e+00],\n",
        "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]).cuda()\n",
        "\n",
        "    width, height = 512, 512\n",
        "    focal_x, focal_y = intrins[0, 0], intrins[1, 1]\n",
        "    viewmat = torch.linalg.inv(c2w).permute(1,0)\n",
        "    FoVx = focal2fov(focal_x, width)\n",
        "    FoVy = focal2fov(focal_y, height)\n",
        "    projmat = getProjectionMatrix(znear=0.2, zfar=1000, fovX=FoVx, fovY=FoVy).transpose(0,1).cuda()\n",
        "    projmat = viewmat @ projmat\n",
        "    return intrins, viewmat, projmat, height, width"
      ],
      "metadata": {
        "id": "lFT5k1dhAX0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization of the 2DGS v.s 3DGS\n",
        "\n",
        "Our 2DGS fits well to a surface."
      ],
      "metadata": {
        "id": "vFfgJKy7R46e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make inputs\n",
        "num_points1=8\n",
        "means3D, scales, quats = get_inputs(num_points=num_points1)\n",
        "intrins, viewmat, projmat, height, width = get_cameras()\n",
        "intrins = intrins[:3,:3]\n",
        "colors = matplotlib.colormaps['Accent'](np.random.randint(1,64, 64)/64)[..., :3]\n",
        "colors = torch.from_numpy(colors).cuda()\n",
        "\n",
        "opacity = torch.ones_like(means3D[:,:1])\n",
        "image1, depthmap1, center1, radii1, dist1 = surface_splatting(means3D, scales, quats, colors, opacity, intrins, viewmat, projmat)\n",
        "image2, depthmap2, center2, radii2, dist2 = volume_splatting(means3D, scales, quats, colors, opacity, intrins, viewmat, projmat)\n",
        "\n",
        "# Visualize 3DGS and 2DGS\n",
        "fig1, (ax1,ax2) = plt.subplots(1,2)\n",
        "fig2, (ax3,ax4) = plt.subplots(1,2)\n",
        "\n",
        "from matplotlib.patches import Rectangle\n",
        "point_image = center1.cpu().detach().numpy()\n",
        "half_extend = radii1.cpu().numpy() * 1/3 # only show one sigma\n",
        "lb = np.floor(point_image - half_extend)[..., :2]\n",
        "hw = np.ceil(2*(half_extend)[..., :2])\n",
        "\n",
        "ax1.set_aspect('equal')\n",
        "ax1.set_axis_off()\n",
        "ax1.set_title('2D Gaussian splatting - color')\n",
        "ax2.set_aspect('equal')\n",
        "ax2.set_axis_off()\n",
        "ax2.set_title('3D Gaussian splatting - color')\n",
        "ax1.set_aspect('equal')\n",
        "ax1.set_axis_off()\n",
        "\n",
        "ax3.set_title('2D Gaussian splatting - depth')\n",
        "ax3.set_axis_off()\n",
        "ax3.set_aspect('equal')\n",
        "ax4.set_axis_off()\n",
        "ax4.set_title('3D Gaussian splatting - depth')\n",
        "fig1.tight_layout()\n",
        "fig2.tight_layout()\n",
        "# visualize AABB\n",
        "for k in range(len(half_extend)):\n",
        "    ax1.add_patch(Rectangle(lb[k], hw[k, 0], hw[k, 1], facecolor='none', edgecolor='white'))\n",
        "    # ax3.add_patch(Rectangle(lb[k], hw[k, 0], hw[k, 1], facecolor='none', edgecolor='white'))\n",
        "\n",
        "img1 = image1.cpu().numpy()\n",
        "img2 = image2.cpu().numpy()\n",
        "ax1.imshow(img1)\n",
        "ax2.imshow(img2)\n",
        "\n",
        "img1 = depthmap1.cpu().numpy()\n",
        "img2 = depthmap2.cpu().numpy()\n",
        "\n",
        "ax3.imshow(img1)\n",
        "ax4.imshow(img2)\n",
        "\n",
        "plt.savefig('test1.png', transparent=True, dpi=300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "K20GoXFJAqzp",
        "outputId": "4fee37a1-023f-4069-9ada-bc8d4b1f1fae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-da78078a9a1d>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Make inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnum_points1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmeans3D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscales\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_points1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mintrins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mviewmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprojmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cameras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mintrins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintrins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-dd1f87bc4d8a>\u001b[0m in \u001b[0;36mget_inputs\u001b[0;34m(num_points)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_points\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeshgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmeans3D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mquats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeans3D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mquats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2DGS V.S flatten 3DGS (setting last scale to be very small)\n",
        "\n",
        "Our 2DGS rasterizer is **perspective correct** and **depth accurate**, with the depth gradient consistent to the the normal direction."
      ],
      "metadata": {
        "id": "0UHcGifCSJ3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reduce num of points to give a close look\n",
        "num_points2=2\n",
        "means3D, scales, quats = get_inputs(num_points=num_points2)\n",
        "scales[:,-1] = 0e-6\n",
        "colors = torch.cat([colors[:num_points2, :], colors[num_points1:num_points1+num_points2, :]], dim=0)\n",
        "\n",
        "opacity = torch.ones_like(means3D[:,:1])\n",
        "\n",
        "image1, depthmap1, center1, radii1, dist1 = surface_splatting(means3D, scales, quats, colors, opacity, intrins, viewmat, projmat)\n",
        "image2, depthmap2, center2, radii2, dist2 = volume_splatting(means3D, scales, quats, colors, opacity, intrins, viewmat, projmat)\n",
        "\n",
        "# Visualize 3DGS and 2DGS\n",
        "fig1, (ax1,ax2) = plt.subplots(1,2)\n",
        "fig2, (ax3,ax4) = plt.subplots(1,2)\n",
        "\n",
        "from matplotlib.patches import Rectangle\n",
        "point_image = center1.cpu().detach().numpy()\n",
        "half_extend = radii1.cpu().numpy()\n",
        "lb = np.floor(point_image - half_extend)[..., :2]\n",
        "hw = np.ceil(2*(half_extend)[..., :2])\n",
        "\n",
        "ax1.set_aspect('equal')\n",
        "ax1.set_axis_off()\n",
        "# ax1.set_title('2D Gaussian splatting - color')\n",
        "ax2.set_aspect('equal')\n",
        "ax2.set_axis_off()\n",
        "# ax2.set_title('3D Gaussian splatting - color')\n",
        "ax1.set_aspect('equal')\n",
        "ax1.set_axis_off()\n",
        "\n",
        "# ax3.set_title('2D Gaussian splatting - depth')\n",
        "ax3.set_axis_off()\n",
        "ax3.set_aspect('equal')\n",
        "ax4.set_axis_off()\n",
        "# ax4.set_title('3D Gaussian splatting - depth')\n",
        "fig1.tight_layout()\n",
        "fig2.tight_layout()\n",
        "\n",
        "img1 = image1.cpu().numpy()\n",
        "img2 = image2.cpu().numpy()\n",
        "ax1.imshow(img1)\n",
        "ax2.imshow(img2)\n",
        "\n",
        "img1 = depthmap1.cpu().numpy()\n",
        "img2 = depthmap2.cpu().numpy()\n",
        "\n",
        "ax3.imshow(img1)\n",
        "ax4.imshow(img2)\n",
        "\n",
        "plt.savefig('test2.png', transparent=True, dpi=300)"
      ],
      "metadata": {
        "id": "LTw-URSvR_it"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "you can see that the flatten 3d Gaussian has perspective distortion and the depth is constant within a splat."
      ],
      "metadata": {
        "id": "O_1mLwSaVk5U"
      }
    }
  ]
}